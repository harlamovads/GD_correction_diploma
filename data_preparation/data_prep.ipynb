{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mistakes = \"/home/zlovoblachko/hse_corpora/rest/data/Exam2014/Task 1/Exam2014_mistakes_table.tsv\"\n",
    "path_sentences = \"/home/zlovoblachko/hse_corpora/rest/data/Exam2014/Task 1/exam2014_new_sentence_text_table.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_mistakes, \"rb\") as f:\n",
    "    mistakes_df = pd.read_csv(f, sep='\\t', encoding='utf-16 LE')\n",
    "\n",
    "with open(path_sentences, \"rb\") as f:\n",
    "    sent_df = pd.read_csv(f, sep='\\t', encoding='utf-16 LE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mistake_id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>mistake_type</th>\n",
       "      <th>error_span</th>\n",
       "      <th>error_span_poses</th>\n",
       "      <th>cause</th>\n",
       "      <th>correction</th>\n",
       "      <th>first_token_id</th>\n",
       "      <th>...</th>\n",
       "      <th>correction_last_token_id</th>\n",
       "      <th>mistake_corrected</th>\n",
       "      <th>correction_tokens</th>\n",
       "      <th>correction_poses</th>\n",
       "      <th>correction_lemmas</th>\n",
       "      <th>correction_token_spaces</th>\n",
       "      <th>ref_1</th>\n",
       "      <th>ref_2</th>\n",
       "      <th>span_start</th>\n",
       "      <th>span_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>T</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>tendention</td>\n",
       "      <td>NN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tendency</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>tendency</td>\n",
       "      <td>NN1</td>\n",
       "      <td>tendency</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>Agreement_errors</td>\n",
       "      <td>visualize</td>\n",
       "      <td>VVB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrates</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>demonstrates</td>\n",
       "      <td>VVZ</td>\n",
       "      <td>demonstrate</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>T</td>\n",
       "      <td>Redundant_comp</td>\n",
       "      <td>part</td>\n",
       "      <td>NN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>509</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>Delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not found</td>\n",
       "      <td>not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>T</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>whew</td>\n",
       "      <td>VVB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>when</td>\n",
       "      <td>AVQ</td>\n",
       "      <td>when</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>687</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mistake_id  text_id  sentence_id ann_id      mistake_type  error_span  \\\n",
       "0           1        1            7      T          Spelling  tendention   \n",
       "1           2        1            1      T  Agreement_errors   visualize   \n",
       "2           3        1            4      T    Redundant_comp        part   \n",
       "3           4        1            4      A            Delete         NaN   \n",
       "4           5        1            5      T          Spelling        whew   \n",
       "\n",
       "  error_span_poses cause    correction  first_token_id  ...  \\\n",
       "0              NN1   NaN      tendency             193  ...   \n",
       "1              VVB   NaN  demonstrates               3  ...   \n",
       "2              NN1   NaN           NaN             108  ...   \n",
       "3              NaN   NaN           NaN             108  ...   \n",
       "4              VVB   NaN          when             149  ...   \n",
       "\n",
       "  correction_last_token_id  mistake_corrected  correction_tokens  \\\n",
       "0                        1               True           tendency   \n",
       "1                        2              False       demonstrates   \n",
       "2                        0              False                NaN   \n",
       "3                        0              False                NaN   \n",
       "4                        3               True               when   \n",
       "\n",
       "   correction_poses correction_lemmas correction_token_spaces ref_1 ref_2  \\\n",
       "0               NN1          tendency                       0   NaN   NaN   \n",
       "1               VVZ       demonstrate                       0   NaN   NaN   \n",
       "2               NaN               NaN                     NaN   NaN   NaN   \n",
       "3               NaN               NaN                     NaN   3.0   NaN   \n",
       "4               AVQ              when                       0   NaN   NaN   \n",
       "\n",
       "   span_start   span_end  \n",
       "0         868        878  \n",
       "1          14         23  \n",
       "2         509        513  \n",
       "3   not found  not found  \n",
       "4         687        691  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentence_poses</th>\n",
       "      <th>sentence_lemmas</th>\n",
       "      <th>sentence_token_spaces</th>\n",
       "      <th>sentence_orig_tokens</th>\n",
       "      <th>sentence_orig_token_spaces</th>\n",
       "      <th>sentence_token_deps</th>\n",
       "      <th>sentence_token_heads</th>\n",
       "      <th>sentence_token_spacy_poses</th>\n",
       "      <th>sentence_token_spacy_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Given diagram visualize the proportion of popu...</td>\n",
       "      <td>AJ0 NN1 VVB AT0 NN1 PRF NN1 PRP CRD CJC AVP PR...</td>\n",
       "      <td>given|give diagram visualize the proportion of...</td>\n",
       "      <td>111111111111011111111101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prep pobj ROOT det dobj prep pobj amod npadvmo...</td>\n",
       "      <td>2 0 2 4 2 4 5 6 7 8 8 4 11 12 12 14 18 18 14 4...</td>\n",
       "      <td>VERB NOUN VERB DET NOUN ADP NOUN VERB NUM CCON...</td>\n",
       "      <td>VBN NN VB DT NN IN NN VBN CD CC RB IN NNP , NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>In all of the countries , the proportion was g...</td>\n",
       "      <td>PRP DT0 PRF AT0 NN2 PUN AT0 NN1 VBD VVG AV0 PR...</td>\n",
       "      <td>in all of the country , the proportion be grow...</td>\n",
       "      <td>111101111111101111101111111101111011101101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prep pobj prep det pobj punct det nsubj aux RO...</td>\n",
       "      <td>9 0 1 4 2 9 7 9 9 9 9 9 13 11 9 9 17 15 19 17 ...</td>\n",
       "      <td>ADP PRON ADP DET NOUN PUNCT DET NOUN AUX VERB ...</td>\n",
       "      <td>IN DT IN DT NNS , DT NN VBD VBG RB IN DT NN , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>After a stable period , we see a huge incline ...</td>\n",
       "      <td>PRP AT0 AJ0 NN1 PUN PNP VVB AT0 AJ0 NN1 CJT VM...</td>\n",
       "      <td>after a stable period , we see a huge incline ...</td>\n",
       "      <td>11101111111111111101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prep det amod pobj punct nsubj ROOT det amod d...</td>\n",
       "      <td>6 3 3 0 6 6 6 9 9 6 12 12 9 12 13 12 15 15 17 6</td>\n",
       "      <td>ADP DET ADJ NOUN PUNCT PRON VERB DET ADJ NOUN ...</td>\n",
       "      <td>IN DT JJ NN , PRP VBP DT JJ NN WDT MD VB IN NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>About a third of a population would be aged 65...</td>\n",
       "      <td>PRP AT0 ORD PRF AT0 NN1 VM0 VBI PRP CRD CJC AV...</td>\n",
       "      <td>about a third of a population would be aged 65...</td>\n",
       "      <td>1111111111111011111011101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advmod quantmod nsubj prep det pobj aux ROOT a...</td>\n",
       "      <td>2 2 7 2 5 3 7 7 7 8 9 9 7 12 7 7 15 15 19 20 2...</td>\n",
       "      <td>ADV DET NOUN ADP DET NOUN AUX AUX VERB NUM CCO...</td>\n",
       "      <td>RB DT NN IN DT NN MD VB VBN CD CC RB IN CD , V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>USA , however , had bigger part of old people ...</td>\n",
       "      <td>NP0 PUN AV0 PUN VHD AJC NN1 PRF AJ0 NN0 PRP AT...</td>\n",
       "      <td>usa , however , have big part of old people th...</td>\n",
       "      <td>0101111111110110111110110111111111101101111101</td>\n",
       "      <td>USA , however , had bigger part of old people ...</td>\n",
       "      <td>0101111111110110111110110111111111101101111101</td>\n",
       "      <td>nsubj punct advmod punct ROOT amod dobj prep a...</td>\n",
       "      <td>4 4 4 4 4 6 4 6 9 7 4 12 10 4 4 16 14 14 17 14...</td>\n",
       "      <td>PROPN PUNCT ADV PUNCT VERB ADJ NOUN ADP ADJ NO...</td>\n",
       "      <td>NNP , RB , VBD JJR NN IN JJ NNS IN DT NN , VBG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  paragraph_id  sentence_id  \\\n",
       "0        1             1            1   \n",
       "1        1             2            2   \n",
       "2        1             3            3   \n",
       "3        1             3            4   \n",
       "4        1             4            5   \n",
       "\n",
       "                                     sentence_tokens  \\\n",
       "0  Given diagram visualize the proportion of popu...   \n",
       "1  In all of the countries , the proportion was g...   \n",
       "2  After a stable period , we see a huge incline ...   \n",
       "3  About a third of a population would be aged 65...   \n",
       "4  USA , however , had bigger part of old people ...   \n",
       "\n",
       "                                      sentence_poses  \\\n",
       "0  AJ0 NN1 VVB AT0 NN1 PRF NN1 PRP CRD CJC AVP PR...   \n",
       "1  PRP DT0 PRF AT0 NN2 PUN AT0 NN1 VBD VVG AV0 PR...   \n",
       "2  PRP AT0 AJ0 NN1 PUN PNP VVB AT0 AJ0 NN1 CJT VM...   \n",
       "3  PRP AT0 ORD PRF AT0 NN1 VM0 VBI PRP CRD CJC AV...   \n",
       "4  NP0 PUN AV0 PUN VHD AJC NN1 PRF AJ0 NN0 PRP AT...   \n",
       "\n",
       "                                     sentence_lemmas  \\\n",
       "0  given|give diagram visualize the proportion of...   \n",
       "1  in all of the country , the proportion be grow...   \n",
       "2  after a stable period , we see a huge incline ...   \n",
       "3  about a third of a population would be aged 65...   \n",
       "4  usa , however , have big part of old people th...   \n",
       "\n",
       "                            sentence_token_spaces  \\\n",
       "0                        111111111111011111111101   \n",
       "1      111101111111101111101111111101111011101101   \n",
       "2                            11101111111111111101   \n",
       "3                       1111111111111011111011101   \n",
       "4  0101111111110110111110110111111111101101111101   \n",
       "\n",
       "                                sentence_orig_tokens  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  USA , however , had bigger part of old people ...   \n",
       "\n",
       "                       sentence_orig_token_spaces  \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4  0101111111110110111110110111111111101101111101   \n",
       "\n",
       "                                 sentence_token_deps  \\\n",
       "0  prep pobj ROOT det dobj prep pobj amod npadvmo...   \n",
       "1  prep pobj prep det pobj punct det nsubj aux RO...   \n",
       "2  prep det amod pobj punct nsubj ROOT det amod d...   \n",
       "3  advmod quantmod nsubj prep det pobj aux ROOT a...   \n",
       "4  nsubj punct advmod punct ROOT amod dobj prep a...   \n",
       "\n",
       "                                sentence_token_heads  \\\n",
       "0  2 0 2 4 2 4 5 6 7 8 8 4 11 12 12 14 18 18 14 4...   \n",
       "1  9 0 1 4 2 9 7 9 9 9 9 9 13 11 9 9 17 15 19 17 ...   \n",
       "2    6 3 3 0 6 6 6 9 9 6 12 12 9 12 13 12 15 15 17 6   \n",
       "3  2 2 7 2 5 3 7 7 7 8 9 9 7 12 7 7 15 15 19 20 2...   \n",
       "4  4 4 4 4 4 6 4 6 9 7 4 12 10 4 4 16 14 14 17 14...   \n",
       "\n",
       "                          sentence_token_spacy_poses  \\\n",
       "0  VERB NOUN VERB DET NOUN ADP NOUN VERB NUM CCON...   \n",
       "1  ADP PRON ADP DET NOUN PUNCT DET NOUN AUX VERB ...   \n",
       "2  ADP DET ADJ NOUN PUNCT PRON VERB DET ADJ NOUN ...   \n",
       "3  ADV DET NOUN ADP DET NOUN AUX AUX VERB NUM CCO...   \n",
       "4  PROPN PUNCT ADV PUNCT VERB ADJ NOUN ADP ADJ NO...   \n",
       "\n",
       "                           sentence_token_spacy_tags  \n",
       "0  VBN NN VB DT NN IN NN VBN CD CC RB IN NNP , NN...  \n",
       "1  IN DT IN DT NNS , DT NN VBD VBG RB IN DT NN , ...  \n",
       "2  IN DT JJ NN , PRP VBP DT JJ NN WDT MD VB IN NN...  \n",
       "3  RB DT NN IN DT NN MD VB VBN CD CC RB IN CD , V...  \n",
       "4  NNP , RB , VBD JJR NN IN JJ NNS IN DT NN , VBG...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_realec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
